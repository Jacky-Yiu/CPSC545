{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8e837f-0115-46c0-a6de-b3dae3ff2fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:23.027776Z",
     "iopub.status.busy": "2023-11-20T20:52:23.027578Z",
     "iopub.status.idle": "2023-11-20T20:52:23.398788Z",
     "shell.execute_reply": "2023-11-20T20:52:23.397955Z",
     "shell.execute_reply.started": "2023-11-20T20:52:23.027754Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/open-problems-single-cell-perturbations/sample_submission.csv\n",
      "/kaggle/input/open-problems-single-cell-perturbations/adata_excluded_ids.csv\n",
      "/kaggle/input/open-problems-single-cell-perturbations/multiome_train.parquet\n",
      "/kaggle/input/open-problems-single-cell-perturbations/multiome_obs_meta.csv\n",
      "/kaggle/input/open-problems-single-cell-perturbations/id_map.csv\n",
      "/kaggle/input/open-problems-single-cell-perturbations/adata_obs_meta.csv\n",
      "/kaggle/input/open-problems-single-cell-perturbations/model.pth\n",
      "/kaggle/input/open-problems-single-cell-perturbations/multiome_var_meta.csv\n",
      "/kaggle/input/open-problems-single-cell-perturbations/adata_train.parquet\n",
      "/kaggle/input/open-problems-single-cell-perturbations/baseline-model (1).ipynb\n",
      "/kaggle/input/open-problems-single-cell-perturbations/de_train.parquet\n",
      "/kaggle/input/open-problems-single-cell-perturbations/Untitled.ipynb\n",
      "/kaggle/input/open-problems-single-cell-perturbations/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
      "/kaggle/input/open-problems-single-cell-perturbations/.ipynb_checkpoints/baseline-model (1)-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1cd22f-72b4-4fff-a06b-98105b65e59b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:23.400732Z",
     "iopub.status.busy": "2023-11-20T20:52:23.400379Z",
     "iopub.status.idle": "2023-11-20T20:52:26.053698Z",
     "shell.execute_reply": "2023-11-20T20:52:26.052858Z",
     "shell.execute_reply.started": "2023-11-20T20:52:23.400706Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (2023.9.1)\n",
      "Requirement already satisfied: numpy in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from rdkit) (1.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from rdkit) (9.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82de1041-ecda-40be-8899-52cdbca2946d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:26.055580Z",
     "iopub.status.busy": "2023-11-20T20:52:26.054996Z",
     "iopub.status.idle": "2023-11-20T20:52:27.271352Z",
     "shell.execute_reply": "2023-11-20T20:52:27.270615Z",
     "shell.execute_reply.started": "2023-11-20T20:52:26.055541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 18216)\n",
      "CPU times: user 1.56 s, sys: 568 ms, total: 2.13 s\n",
      "Wall time: 1.19 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>sm_name</th>\n",
       "      <th>sm_lincs_id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>control</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1BG-AS1</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2M-AS1</th>\n",
       "      <th>A2MP1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZUP1</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NK cells</td>\n",
       "      <td>Clotrimazole</td>\n",
       "      <td>LSM-5341</td>\n",
       "      <td>Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>-0.077524</td>\n",
       "      <td>-1.625596</td>\n",
       "      <td>-0.144545</td>\n",
       "      <td>0.143555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227781</td>\n",
       "      <td>-0.010752</td>\n",
       "      <td>-0.023881</td>\n",
       "      <td>0.674536</td>\n",
       "      <td>-0.453068</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>-0.094959</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>0.221377</td>\n",
       "      <td>0.368755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T cells CD4+</td>\n",
       "      <td>Clotrimazole</td>\n",
       "      <td>LSM-5341</td>\n",
       "      <td>Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915953</td>\n",
       "      <td>-0.884380</td>\n",
       "      <td>0.371834</td>\n",
       "      <td>-0.081677</td>\n",
       "      <td>-0.498266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494985</td>\n",
       "      <td>-0.303419</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>-0.315516</td>\n",
       "      <td>-0.369626</td>\n",
       "      <td>-0.095079</td>\n",
       "      <td>0.704780</td>\n",
       "      <td>1.096702</td>\n",
       "      <td>-0.869887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T cells CD8+</td>\n",
       "      <td>Clotrimazole</td>\n",
       "      <td>LSM-5341</td>\n",
       "      <td>Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.387721</td>\n",
       "      <td>-0.305378</td>\n",
       "      <td>0.567777</td>\n",
       "      <td>0.303895</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119422</td>\n",
       "      <td>-0.033608</td>\n",
       "      <td>-0.153123</td>\n",
       "      <td>0.183597</td>\n",
       "      <td>-0.555678</td>\n",
       "      <td>-1.494789</td>\n",
       "      <td>-0.213550</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.078439</td>\n",
       "      <td>-0.259365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T regulatory cells</td>\n",
       "      <td>Clotrimazole</td>\n",
       "      <td>LSM-5341</td>\n",
       "      <td>Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.232893</td>\n",
       "      <td>0.129029</td>\n",
       "      <td>0.336897</td>\n",
       "      <td>0.486946</td>\n",
       "      <td>0.767661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451679</td>\n",
       "      <td>0.704643</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>-0.103868</td>\n",
       "      <td>0.865027</td>\n",
       "      <td>0.189114</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>-0.048233</td>\n",
       "      <td>0.216139</td>\n",
       "      <td>-0.085024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NK cells</td>\n",
       "      <td>Mometasone Furoate</td>\n",
       "      <td>LSM-3349</td>\n",
       "      <td>C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.290652</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>-0.017443</td>\n",
       "      <td>-0.541154</td>\n",
       "      <td>0.570982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758474</td>\n",
       "      <td>0.510762</td>\n",
       "      <td>0.607401</td>\n",
       "      <td>-0.123059</td>\n",
       "      <td>0.214366</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>-0.819775</td>\n",
       "      <td>0.112365</td>\n",
       "      <td>-0.122193</td>\n",
       "      <td>0.676629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>T regulatory cells</td>\n",
       "      <td>Atorvastatin</td>\n",
       "      <td>LSM-5771</td>\n",
       "      <td>CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014372</td>\n",
       "      <td>-0.122464</td>\n",
       "      <td>-0.456366</td>\n",
       "      <td>-0.147894</td>\n",
       "      <td>-0.545382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549987</td>\n",
       "      <td>-2.200925</td>\n",
       "      <td>0.359806</td>\n",
       "      <td>1.073983</td>\n",
       "      <td>0.356939</td>\n",
       "      <td>-0.029603</td>\n",
       "      <td>-0.528817</td>\n",
       "      <td>0.105138</td>\n",
       "      <td>0.491015</td>\n",
       "      <td>-0.979951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NK cells</td>\n",
       "      <td>Riociguat</td>\n",
       "      <td>LSM-45758</td>\n",
       "      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.455549</td>\n",
       "      <td>0.188181</td>\n",
       "      <td>0.595734</td>\n",
       "      <td>-0.100299</td>\n",
       "      <td>0.786192</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.236905</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>-0.197569</td>\n",
       "      <td>-0.175307</td>\n",
       "      <td>0.101391</td>\n",
       "      <td>1.028394</td>\n",
       "      <td>0.034144</td>\n",
       "      <td>-0.231642</td>\n",
       "      <td>1.023994</td>\n",
       "      <td>-0.064760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>T cells CD4+</td>\n",
       "      <td>Riociguat</td>\n",
       "      <td>LSM-45758</td>\n",
       "      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.338168</td>\n",
       "      <td>-0.109079</td>\n",
       "      <td>0.270182</td>\n",
       "      <td>-0.436586</td>\n",
       "      <td>-0.069476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077579</td>\n",
       "      <td>-1.101637</td>\n",
       "      <td>0.457201</td>\n",
       "      <td>0.535184</td>\n",
       "      <td>-0.198404</td>\n",
       "      <td>-0.005004</td>\n",
       "      <td>0.552810</td>\n",
       "      <td>-0.209077</td>\n",
       "      <td>0.389751</td>\n",
       "      <td>-0.337082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>T cells CD8+</td>\n",
       "      <td>Riociguat</td>\n",
       "      <td>LSM-45758</td>\n",
       "      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.101138</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.606292</td>\n",
       "      <td>-0.071300</td>\n",
       "      <td>-0.001789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>-0.893093</td>\n",
       "      <td>-1.003029</td>\n",
       "      <td>-0.080367</td>\n",
       "      <td>-0.076604</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>-0.029684</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>-1.733112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>T regulatory cells</td>\n",
       "      <td>Riociguat</td>\n",
       "      <td>LSM-45758</td>\n",
       "      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.757116</td>\n",
       "      <td>0.085910</td>\n",
       "      <td>-0.730025</td>\n",
       "      <td>-1.367801</td>\n",
       "      <td>-0.695944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232343</td>\n",
       "      <td>-2.247816</td>\n",
       "      <td>-0.346036</td>\n",
       "      <td>-0.919567</td>\n",
       "      <td>-1.131372</td>\n",
       "      <td>-0.120252</td>\n",
       "      <td>-0.064537</td>\n",
       "      <td>-0.603280</td>\n",
       "      <td>-0.098041</td>\n",
       "      <td>-0.750681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 18216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cell_type             sm_name sm_lincs_id  \\\n",
       "0              NK cells        Clotrimazole    LSM-5341   \n",
       "1          T cells CD4+        Clotrimazole    LSM-5341   \n",
       "2          T cells CD8+        Clotrimazole    LSM-5341   \n",
       "3    T regulatory cells        Clotrimazole    LSM-5341   \n",
       "4              NK cells  Mometasone Furoate    LSM-3349   \n",
       "..                  ...                 ...         ...   \n",
       "609  T regulatory cells        Atorvastatin    LSM-5771   \n",
       "610            NK cells           Riociguat   LSM-45758   \n",
       "611        T cells CD4+           Riociguat   LSM-45758   \n",
       "612        T cells CD8+           Riociguat   LSM-45758   \n",
       "613  T regulatory cells           Riociguat   LSM-45758   \n",
       "\n",
       "                                                SMILES  control      A1BG  \\\n",
       "0               Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.104720   \n",
       "1               Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.915953   \n",
       "2               Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False -0.387721   \n",
       "3               Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.232893   \n",
       "4    C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...    False  4.290652   \n",
       "..                                                 ...      ...       ...   \n",
       "609  CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F...    False -0.014372   \n",
       "610  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False -0.455549   \n",
       "611  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False  0.338168   \n",
       "612  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False  0.101138   \n",
       "613  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False -0.757116   \n",
       "\n",
       "     A1BG-AS1       A2M   A2M-AS1     A2MP1  ...      ZUP1      ZW10  \\\n",
       "0   -0.077524 -1.625596 -0.144545  0.143555  ... -0.227781 -0.010752   \n",
       "1   -0.884380  0.371834 -0.081677 -0.498266  ... -0.494985 -0.303419   \n",
       "2   -0.305378  0.567777  0.303895 -0.022653  ... -0.119422 -0.033608   \n",
       "3    0.129029  0.336897  0.486946  0.767661  ...  0.451679  0.704643   \n",
       "4   -0.063864 -0.017443 -0.541154  0.570982  ...  0.758474  0.510762   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "609 -0.122464 -0.456366 -0.147894 -0.545382  ... -0.549987 -2.200925   \n",
       "610  0.188181  0.595734 -0.100299  0.786192  ... -1.236905  0.003854   \n",
       "611 -0.109079  0.270182 -0.436586 -0.069476  ...  0.077579 -1.101637   \n",
       "612 -0.409724 -0.606292 -0.071300 -0.001789  ...  0.005951 -0.893093   \n",
       "613  0.085910 -0.730025 -1.367801 -0.695944  ...  0.232343 -2.247816   \n",
       "\n",
       "       ZWILCH     ZWINT      ZXDA      ZXDB      ZXDC    ZYG11B       ZYX  \\\n",
       "0   -0.023881  0.674536 -0.453068  0.005164 -0.094959  0.034127  0.221377   \n",
       "1    0.304955 -0.333905 -0.315516 -0.369626 -0.095079  0.704780  1.096702   \n",
       "2   -0.153123  0.183597 -0.555678 -1.494789 -0.213550  0.415768  0.078439   \n",
       "3    0.015468 -0.103868  0.865027  0.189114  0.224700 -0.048233  0.216139   \n",
       "4    0.607401 -0.123059  0.214366  0.487838 -0.819775  0.112365 -0.122193   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "609  0.359806  1.073983  0.356939 -0.029603 -0.528817  0.105138  0.491015   \n",
       "610 -0.197569 -0.175307  0.101391  1.028394  0.034144 -0.231642  1.023994   \n",
       "611  0.457201  0.535184 -0.198404 -0.005004  0.552810 -0.209077  0.389751   \n",
       "612 -1.003029 -0.080367 -0.076604  0.024849  0.012862 -0.029684  0.005506   \n",
       "613 -0.346036 -0.919567 -1.131372 -0.120252 -0.064537 -0.603280 -0.098041   \n",
       "\n",
       "        ZZEF1  \n",
       "0    0.368755  \n",
       "1   -0.869887  \n",
       "2   -0.259365  \n",
       "3   -0.085024  \n",
       "4    0.676629  \n",
       "..        ...  \n",
       "609 -0.979951  \n",
       "610 -0.064760  \n",
       "611 -0.337082  \n",
       "612 -1.733112  \n",
       "613 -0.750681  \n",
       "\n",
       "[614 rows x 18216 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fn = '/kaggle/input/open-problems-single-cell-perturbations/de_train.parquet'\n",
    "df_de_train = pd.read_parquet(fn)# , index_col = 0)\n",
    "print(df_de_train.shape)\n",
    "df_de_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3954e7-efee-401d-875a-183db2f8df4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:27.273236Z",
     "iopub.status.busy": "2023-11-20T20:52:27.272611Z",
     "iopub.status.idle": "2023-11-20T20:52:27.278708Z",
     "shell.execute_reply": "2023-11-20T20:52:27.277976Z",
     "shell.execute_reply.started": "2023-11-20T20:52:27.273198Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one hot encode cells\n",
    "df_de_train.cell_type\n",
    "\n",
    "cell_type_one_hot_encoded_data = pd.get_dummies(df_de_train['cell_type'], prefix='cell_type')\n",
    "# len(set(one_hot_encoded_data)) # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6853bb36-6fd9-4a1e-a6f5-a523fdf469cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:27.279903Z",
     "iopub.status.busy": "2023-11-20T20:52:27.279640Z",
     "iopub.status.idle": "2023-11-20T20:52:27.327332Z",
     "shell.execute_reply": "2023-11-20T20:52:27.326483Z",
     "shell.execute_reply.started": "2023-11-20T20:52:27.279881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1BG-AS1</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2M-AS1</th>\n",
       "      <th>A2MP1</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AAGAB</th>\n",
       "      <th>AAK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZUP1</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104720</td>\n",
       "      <td>-0.077524</td>\n",
       "      <td>-1.625596</td>\n",
       "      <td>-0.144545</td>\n",
       "      <td>0.143555</td>\n",
       "      <td>0.073229</td>\n",
       "      <td>-0.016823</td>\n",
       "      <td>0.101717</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>1.043629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227781</td>\n",
       "      <td>-0.010752</td>\n",
       "      <td>-0.023881</td>\n",
       "      <td>0.674536</td>\n",
       "      <td>-0.453068</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>-0.094959</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>0.221377</td>\n",
       "      <td>0.368755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915953</td>\n",
       "      <td>-0.884380</td>\n",
       "      <td>0.371834</td>\n",
       "      <td>-0.081677</td>\n",
       "      <td>-0.498266</td>\n",
       "      <td>0.203559</td>\n",
       "      <td>0.604656</td>\n",
       "      <td>0.498592</td>\n",
       "      <td>-0.317184</td>\n",
       "      <td>0.375550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494985</td>\n",
       "      <td>-0.303419</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>-0.315516</td>\n",
       "      <td>-0.369626</td>\n",
       "      <td>-0.095079</td>\n",
       "      <td>0.704780</td>\n",
       "      <td>1.096702</td>\n",
       "      <td>-0.869887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.387721</td>\n",
       "      <td>-0.305378</td>\n",
       "      <td>0.567777</td>\n",
       "      <td>0.303895</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.480681</td>\n",
       "      <td>0.467144</td>\n",
       "      <td>-0.293205</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>0.214918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119422</td>\n",
       "      <td>-0.033608</td>\n",
       "      <td>-0.153123</td>\n",
       "      <td>0.183597</td>\n",
       "      <td>-0.555678</td>\n",
       "      <td>-1.494789</td>\n",
       "      <td>-0.213550</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.078439</td>\n",
       "      <td>-0.259365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.232893</td>\n",
       "      <td>0.129029</td>\n",
       "      <td>0.336897</td>\n",
       "      <td>0.486946</td>\n",
       "      <td>0.767661</td>\n",
       "      <td>0.718590</td>\n",
       "      <td>-0.162145</td>\n",
       "      <td>0.157206</td>\n",
       "      <td>-3.654218</td>\n",
       "      <td>-0.212402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451679</td>\n",
       "      <td>0.704643</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>-0.103868</td>\n",
       "      <td>0.865027</td>\n",
       "      <td>0.189114</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>-0.048233</td>\n",
       "      <td>0.216139</td>\n",
       "      <td>-0.085024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.290652</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>-0.017443</td>\n",
       "      <td>-0.541154</td>\n",
       "      <td>0.570982</td>\n",
       "      <td>2.022829</td>\n",
       "      <td>0.600011</td>\n",
       "      <td>1.231275</td>\n",
       "      <td>0.236739</td>\n",
       "      <td>0.338703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758474</td>\n",
       "      <td>0.510762</td>\n",
       "      <td>0.607401</td>\n",
       "      <td>-0.123059</td>\n",
       "      <td>0.214366</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>-0.819775</td>\n",
       "      <td>0.112365</td>\n",
       "      <td>-0.122193</td>\n",
       "      <td>0.676629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A1BG  A1BG-AS1       A2M   A2M-AS1     A2MP1    A4GALT      AAAS  \\\n",
       "0  0.104720 -0.077524 -1.625596 -0.144545  0.143555  0.073229 -0.016823   \n",
       "1  0.915953 -0.884380  0.371834 -0.081677 -0.498266  0.203559  0.604656   \n",
       "2 -0.387721 -0.305378  0.567777  0.303895 -0.022653 -0.480681  0.467144   \n",
       "3  0.232893  0.129029  0.336897  0.486946  0.767661  0.718590 -0.162145   \n",
       "4  4.290652 -0.063864 -0.017443 -0.541154  0.570982  2.022829  0.600011   \n",
       "\n",
       "       AACS     AAGAB      AAK1  ...      ZUP1      ZW10    ZWILCH     ZWINT  \\\n",
       "0  0.101717 -0.005153  1.043629  ... -0.227781 -0.010752 -0.023881  0.674536   \n",
       "1  0.498592 -0.317184  0.375550  ... -0.494985 -0.303419  0.304955 -0.333905   \n",
       "2 -0.293205 -0.005098  0.214918  ... -0.119422 -0.033608 -0.153123  0.183597   \n",
       "3  0.157206 -3.654218 -0.212402  ...  0.451679  0.704643  0.015468 -0.103868   \n",
       "4  1.231275  0.236739  0.338703  ...  0.758474  0.510762  0.607401 -0.123059   \n",
       "\n",
       "       ZXDA      ZXDB      ZXDC    ZYG11B       ZYX     ZZEF1  \n",
       "0 -0.453068  0.005164 -0.094959  0.034127  0.221377  0.368755  \n",
       "1 -0.315516 -0.369626 -0.095079  0.704780  1.096702 -0.869887  \n",
       "2 -0.555678 -1.494789 -0.213550  0.415768  0.078439 -0.259365  \n",
       "3  0.865027  0.189114  0.224700 -0.048233  0.216139 -0.085024  \n",
       "4  0.214366  0.487838 -0.819775  0.112365 -0.122193  0.676629  \n",
       "\n",
       "[5 rows x 18211 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differential_expressions = df_de_train.iloc[:,5:]\n",
    "differential_expressions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b4c872-9fcc-4a3b-8efa-105d8b960089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:27.328491Z",
     "iopub.status.busy": "2023-11-20T20:52:27.328258Z",
     "iopub.status.idle": "2023-11-20T20:52:27.898855Z",
     "shell.execute_reply": "2023-11-20T20:52:27.898155Z",
     "shell.execute_reply.started": "2023-11-20T20:52:27.328470Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     bit_0  bit_1  bit_2  bit_3  bit_4  bit_5  bit_6  bit_7  bit_8  bit_9  \\\n",
      "0        0      0      0      0      0      0      0      0      1      0   \n",
      "1        0      0      0      0      0      0      0      0      1      0   \n",
      "2        0      0      0      0      0      0      0      0      1      0   \n",
      "3        0      0      0      0      0      0      0      0      1      0   \n",
      "4        0      0      0      0      0      0      0      1      0      0   \n",
      "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "609      0      1      0      0      0      0      0      0      0      0   \n",
      "610      0      0      0      0      1      0      0      0      1      0   \n",
      "611      0      0      0      0      1      0      0      0      1      0   \n",
      "612      0      0      0      0      1      0      0      0      1      0   \n",
      "613      0      0      0      0      1      0      0      0      1      0   \n",
      "\n",
      "     ...  bit_246  bit_247  bit_248  bit_249  bit_250  bit_251  bit_252  \\\n",
      "0    ...        0        0        0        0        0        0        0   \n",
      "1    ...        0        0        0        0        0        0        0   \n",
      "2    ...        0        0        0        0        0        0        0   \n",
      "3    ...        0        0        0        0        0        0        0   \n",
      "4    ...        0        0        1        0        1        1        0   \n",
      "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "609  ...        1        0        0        0        0        0        0   \n",
      "610  ...        0        0        0        0        0        0        0   \n",
      "611  ...        0        0        0        0        0        0        0   \n",
      "612  ...        0        0        0        0        0        0        0   \n",
      "613  ...        0        0        0        0        0        0        0   \n",
      "\n",
      "     bit_253  bit_254  bit_255  \n",
      "0          0        0        0  \n",
      "1          0        0        0  \n",
      "2          0        0        0  \n",
      "3          0        0        0  \n",
      "4          0        0        1  \n",
      "..       ...      ...      ...  \n",
      "609        0        0        0  \n",
      "610        0        1        0  \n",
      "611        0        1        0  \n",
      "612        0        1        0  \n",
      "613        0        1        0  \n",
      "\n",
      "[614 rows x 256 columns]\n",
      "Sparsity of the matrix: 80.74%\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "data = df_de_train\n",
    "\n",
    "\n",
    "fingerprints = []\n",
    "for smiles in data['SMILES']:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=256)\n",
    "    fingerprint_list = list(fp)\n",
    "    fingerprints.append(fingerprint_list)\n",
    "\n",
    "# Convert the fingerprints to a DataFrame and combine with the original data\n",
    "fingerprint_df = pd.DataFrame(fingerprints, columns=[f'bit_{i}' for i in range(256)])  # Change 2048 to your fingerprint size\n",
    "#result = pd.concat([data, fingerprint_df], axis=1)\n",
    "\n",
    "# Now 'result' contains the original data along with the generated molecular fingerprints\n",
    "print(fingerprint_df)\n",
    "\n",
    "sparsity = 1.0 - np.count_nonzero(fingerprint_df) / fingerprint_df.size\n",
    "sparsity_percentage = sparsity * 100\n",
    "\n",
    "print(f\"Sparsity of the matrix: {sparsity_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3509ad46-d173-443d-a0be-08e7e0eb0013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:27.901135Z",
     "iopub.status.busy": "2023-11-20T20:52:27.900799Z",
     "iopub.status.idle": "2023-11-20T20:52:36.593478Z",
     "shell.execute_reply": "2023-11-20T20:52:36.592621Z",
     "shell.execute_reply.started": "2023-11-20T20:52:27.901097Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n",
      "0           6.691467        6.691467           0.585949       -0.585949   \n",
      "1           6.691467        6.691467           0.585949       -0.585949   \n",
      "2           6.691467        6.691467           0.585949       -0.585949   \n",
      "3           6.691467        6.691467           0.585949       -0.585949   \n",
      "4          13.573161       13.573161           0.005567       -1.529881   \n",
      "\n",
      "        qed        SPS    MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
      "0  0.454545  11.400000  344.845         327.709  344.108026   \n",
      "1  0.454545  11.400000  344.845         327.709  344.108026   \n",
      "2  0.454545  11.400000  344.845         327.709  344.108026   \n",
      "3  0.454545  11.400000  344.845         327.709  344.108026   \n",
      "4  0.449102  44.171429  521.437         491.197  520.141944   \n",
      "\n",
      "   NumValenceElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
      "0                  122  ...           0             0           0   \n",
      "1                  122  ...           0             0           0   \n",
      "2                  122  ...           0             0           0   \n",
      "3                  122  ...           0             0           0   \n",
      "4                  188  ...           0             0           0   \n",
      "\n",
      "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
      "0                  0             0            0            0             0   \n",
      "1                  0             0            0            0             0   \n",
      "2                  0             0            0            0             0   \n",
      "3                  0             0            0            0             0   \n",
      "4                  0             0            0            0             0   \n",
      "\n",
      "   fr_unbrch_alkane  fr_urea  \n",
      "0                 0        0  \n",
      "1                 0        0  \n",
      "2                 0        0  \n",
      "3                 0        0  \n",
      "4                 0        0  \n",
      "\n",
      "[5 rows x 210 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# Read your dataset\n",
    "data = df_de_train\n",
    "\n",
    "descriptors = []\n",
    "for smiles in data['SMILES']:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        desc = {'SMILES': smiles}\n",
    "        for desc_name, desc_func in Descriptors.descList:\n",
    "            try:\n",
    "                value = desc_func(mol)\n",
    "                if isinstance(value, (int, float)):\n",
    "                    desc[desc_name] = value\n",
    "            except:\n",
    "                pass\n",
    "        descriptors.append(desc)\n",
    "        \n",
    "# Convert the descriptors to a DataFrame and combine with the original data\n",
    "descriptors_df = pd.DataFrame(descriptors)\n",
    "descriptors_df = descriptors_df.drop(columns=['SMILES'])\n",
    "\n",
    "# Now 'result' contains the original data along with the calculated molecular descriptors\n",
    "print(descriptors_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6436cf6a-341a-451a-9088-b52176db5593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:36.595283Z",
     "iopub.status.busy": "2023-11-20T20:52:36.594678Z",
     "iopub.status.idle": "2023-11-20T20:52:36.636670Z",
     "shell.execute_reply": "2023-11-20T20:52:36.635800Z",
     "shell.execute_reply.started": "2023-11-20T20:52:36.595245Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bit_0</th>\n",
       "      <th>bit_1</th>\n",
       "      <th>bit_2</th>\n",
       "      <th>bit_3</th>\n",
       "      <th>bit_4</th>\n",
       "      <th>bit_5</th>\n",
       "      <th>bit_6</th>\n",
       "      <th>bit_7</th>\n",
       "      <th>bit_8</th>\n",
       "      <th>bit_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_piperzine</th>\n",
       "      <th>fr_priamide</th>\n",
       "      <th>fr_pyridine</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bit_0  bit_1  bit_2  bit_3  bit_4  bit_5  bit_6  bit_7  bit_8  bit_9  ...  \\\n",
       "0      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "2      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "4      0      0      0      0      0      0      0      1      0      0  ...   \n",
       "\n",
       "   fr_piperzine  fr_priamide  fr_pyridine  fr_sulfide  fr_sulfonamd  \\\n",
       "0             0            0            0           0             0   \n",
       "1             0            0            0           0             0   \n",
       "2             0            0            0           0             0   \n",
       "3             0            0            0           0             0   \n",
       "4             0            0            0           0             0   \n",
       "\n",
       "   fr_sulfone  fr_thiazole  fr_thiophene  fr_unbrch_alkane  fr_urea  \n",
       "0           0            0             0                 0        0  \n",
       "1           0            0             0                 0        0  \n",
       "2           0            0             0                 0        0  \n",
       "3           0            0             0                 0        0  \n",
       "4           0            0             0                 0        0  \n",
       "\n",
       "[5 rows x 441 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_drug_info = pd.concat([fingerprint_df, descriptors_df], axis=1)\n",
    "combined_drug_info = combined_drug_info.loc[:, combined_drug_info.nunique() != 1]\n",
    "\n",
    "combined_drug_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91b9839-d4ad-4bb4-90a2-82d60358eadf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:36.637914Z",
     "iopub.status.busy": "2023-11-20T20:52:36.637638Z",
     "iopub.status.idle": "2023-11-20T20:52:36.687084Z",
     "shell.execute_reply": "2023-11-20T20:52:36.686432Z",
     "shell.execute_reply.started": "2023-11-20T20:52:36.637891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bit_0</th>\n",
       "      <th>bit_1</th>\n",
       "      <th>bit_2</th>\n",
       "      <th>bit_3</th>\n",
       "      <th>bit_4</th>\n",
       "      <th>bit_5</th>\n",
       "      <th>bit_6</th>\n",
       "      <th>bit_7</th>\n",
       "      <th>bit_8</th>\n",
       "      <th>bit_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ZUP1</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227781</td>\n",
       "      <td>-0.010752</td>\n",
       "      <td>-0.023881</td>\n",
       "      <td>0.674536</td>\n",
       "      <td>-0.453068</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>-0.094959</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>0.221377</td>\n",
       "      <td>0.368755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494985</td>\n",
       "      <td>-0.303419</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>-0.315516</td>\n",
       "      <td>-0.369626</td>\n",
       "      <td>-0.095079</td>\n",
       "      <td>0.704780</td>\n",
       "      <td>1.096702</td>\n",
       "      <td>-0.869887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119422</td>\n",
       "      <td>-0.033608</td>\n",
       "      <td>-0.153123</td>\n",
       "      <td>0.183597</td>\n",
       "      <td>-0.555678</td>\n",
       "      <td>-1.494789</td>\n",
       "      <td>-0.213550</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.078439</td>\n",
       "      <td>-0.259365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451679</td>\n",
       "      <td>0.704643</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>-0.103868</td>\n",
       "      <td>0.865027</td>\n",
       "      <td>0.189114</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>-0.048233</td>\n",
       "      <td>0.216139</td>\n",
       "      <td>-0.085024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758474</td>\n",
       "      <td>0.510762</td>\n",
       "      <td>0.607401</td>\n",
       "      <td>-0.123059</td>\n",
       "      <td>0.214366</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>-0.819775</td>\n",
       "      <td>0.112365</td>\n",
       "      <td>-0.122193</td>\n",
       "      <td>0.676629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bit_0  bit_1  bit_2  bit_3  bit_4  bit_5  bit_6  bit_7  bit_8  bit_9  ...  \\\n",
       "0      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "2      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      1      0  ...   \n",
       "4      0      0      0      0      0      0      0      1      0      0  ...   \n",
       "\n",
       "       ZUP1      ZW10    ZWILCH     ZWINT      ZXDA      ZXDB      ZXDC  \\\n",
       "0 -0.227781 -0.010752 -0.023881  0.674536 -0.453068  0.005164 -0.094959   \n",
       "1 -0.494985 -0.303419  0.304955 -0.333905 -0.315516 -0.369626 -0.095079   \n",
       "2 -0.119422 -0.033608 -0.153123  0.183597 -0.555678 -1.494789 -0.213550   \n",
       "3  0.451679  0.704643  0.015468 -0.103868  0.865027  0.189114  0.224700   \n",
       "4  0.758474  0.510762  0.607401 -0.123059  0.214366  0.487838 -0.819775   \n",
       "\n",
       "     ZYG11B       ZYX     ZZEF1  \n",
       "0  0.034127  0.221377  0.368755  \n",
       "1  0.704780  1.096702 -0.869887  \n",
       "2  0.415768  0.078439 -0.259365  \n",
       "3 -0.048233  0.216139 -0.085024  \n",
       "4  0.112365 -0.122193  0.676629  \n",
       "\n",
       "[5 rows x 18658 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_drug_cell_DE = pd.concat([combined_drug_info, cell_type_one_hot_encoded_data, differential_expressions], axis=1)\n",
    "combined_drug_cell_DE.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbed1b21-59c6-4a4b-90ad-b1948d023ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:52:36.688345Z",
     "iopub.status.busy": "2023-11-20T20:52:36.688045Z",
     "iopub.status.idle": "2023-11-20T20:52:36.692814Z",
     "shell.execute_reply": "2023-11-20T20:52:36.692162Z",
     "shell.execute_reply.started": "2023-11-20T20:52:36.688321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 18658)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_drug_cell_DE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b18ba9b-e28c-47db-b8eb-116668f7338c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T21:06:40.092543Z",
     "iopub.status.busy": "2023-11-20T21:06:40.091980Z",
     "iopub.status.idle": "2023-11-20T21:06:40.105533Z",
     "shell.execute_reply": "2023-11-20T21:06:40.104891Z",
     "shell.execute_reply.started": "2023-11-20T21:06:40.092510Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LargeVAE(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, dropout_rate=0.5):\n",
    "        super(LargeVAE, self).__init__()\n",
    "        \n",
    "        base_multiplier = 2 *2 * 2 * 2 \n",
    "        \n",
    "        # Encoder\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, 512 * base_multiplier)\n",
    "        self.ln1 = nn.LayerNorm(512* base_multiplier)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)  # Dropout layer after first FC\n",
    "\n",
    "        self.fc2 = nn.Linear(512* base_multiplier, 256 * base_multiplier)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)  # Dropout layer after second FC\n",
    "        self.fc3_mean = nn.Linear(256* base_multiplier, latent_size)\n",
    "        self.fc3_logvar = nn.Linear(256 * base_multiplier, latent_size)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc4 = nn.Linear(latent_size, 512 * base_multiplier)\n",
    "        self.fc5 = nn.Linear(512 * base_multiplier, 512 * base_multiplier)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)  # Dropout layer in Decoder\n",
    "        self.fc6 = nn.Linear(512 * base_multiplier, input_size)\n",
    "        \n",
    "        # Apply Kaiming Initialization\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.bn(x)\n",
    "        h1 = F.relu(self.ln1(self.fc1(x)))\n",
    "        h1 = self.dropout1(h1)  # Apply dropout\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        h2 = self.dropout2(h2)  # Apply dropout\n",
    "        return self.fc3_mean(h2), self.fc3_logvar(h2)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc4(z))\n",
    "        h4 = F.relu(self.fc5(h3))\n",
    "        h4 = self.dropout3(h4)  # Apply dropout\n",
    "        return self.fc6(h4)  # No activation function, i.e., linear activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decode(z), mean, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mean, logvar):\n",
    "    # MSE loss for reconstruction\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "\n",
    "    # KL divergence loss, with small epsilon for numerical stability\n",
    "    eps = 1e-8\n",
    "    KL_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - (logvar.exp() + eps))\n",
    "\n",
    "    # Total loss is the sum of reconstruction loss and KL divergence loss\n",
    "    total_loss = recon_loss + KL_loss\n",
    "    return total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1798d3a5-c091-421f-8c88-1cdbd802e086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T21:06:40.107423Z",
     "iopub.status.busy": "2023-11-20T21:06:40.107090Z",
     "iopub.status.idle": "2023-11-20T21:06:40.276666Z",
     "shell.execute_reply": "2023-11-20T21:06:40.275886Z",
     "shell.execute_reply.started": "2023-11-20T21:06:40.107388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Assuming `combined_drug_cell_DE` is your dataset in a pandas DataFrame or NumPy array\n",
    "X = torch.tensor(combined_drug_cell_DE.values, dtype=torch.float32)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_data, train_data)\n",
    "val_dataset = TensorDataset(val_data, val_data)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 128*2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d6715aa-5bd2-4556-bf33-7b01662f9648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T21:06:40.277929Z",
     "iopub.status.busy": "2023-11-20T21:06:40.277612Z",
     "iopub.status.idle": "2023-11-20T21:06:40.282905Z",
     "shell.execute_reply": "2023-11-20T21:06:40.282288Z",
     "shell.execute_reply.started": "2023-11-20T21:06:40.277904Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_rowwise_rmse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function to calculate the Mean Rowwise Root Mean Squared Error (RMSE) loss.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: The true target values.\n",
    "    - y_pred: The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    - Mean Rowwise RMSE loss as a scalar tensor.\n",
    "    \"\"\"\n",
    "    # Calculate RMSE for each row\n",
    "    rmse_per_row = torch.sqrt(torch.mean((y_true - y_pred) ** 2, dim=1))\n",
    "    # Calculate the mean of RMSE values across all rows\n",
    "    mean_rmse = torch.mean(rmse_per_row)\n",
    "\n",
    "    return mean_rmse\n",
    "\n",
    "def loss_function(recon_x, x, mean, logvar):\n",
    "    # RWRMSE loss for reconstruction\n",
    "    recon_loss = mean_rowwise_rmse_loss(recon_x, x)\n",
    "\n",
    "    # KL divergence loss\n",
    "    KL_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "    # Total loss is the sum of reconstruction loss and KL divergence loss\n",
    "    total_loss = recon_loss + KL_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f53dcd-dafe-464f-9649-a90e2b452fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T21:06:40.284250Z",
     "iopub.status.busy": "2023-11-20T21:06:40.284015Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000], Train Loss: 34177151.2179\n",
      "Epoch [2/5000], Train Loss: 35050825.5153\n",
      "Epoch [2/5000], Validation Loss: 63765370.7967\n",
      "new smallest validation loss\n",
      "Epoch [3/5000], Train Loss: 34160460.6436\n",
      "Epoch [22/5000], Validation Loss: 63765291.7073\n",
      "new smallest validation loss\n",
      "Epoch [42/5000], Validation Loss: 63765291.7073\n",
      "Epoch [62/5000], Validation Loss: 63765291.7073\n",
      "Epoch [82/5000], Validation Loss: 63765291.7073\n",
      "Epoch [101/5000], Train Loss: 33955659.6008\n",
      "Epoch [102/5000], Train Loss: 34173334.6802\n",
      "Epoch [102/5000], Validation Loss: 63765291.7073\n",
      "Epoch [103/5000], Train Loss: 34822085.6049\n",
      "Epoch [122/5000], Validation Loss: 63765291.7073\n",
      "Epoch [142/5000], Validation Loss: 63765291.7073\n",
      "Epoch [162/5000], Validation Loss: 63765287.5447\n",
      "new smallest validation loss\n",
      "Epoch [182/5000], Validation Loss: 63765287.5447\n",
      "Epoch [201/5000], Train Loss: 34845978.5906\n",
      "Epoch [202/5000], Train Loss: 34615841.3686\n",
      "Epoch [202/5000], Validation Loss: 63765287.5447\n",
      "Epoch [203/5000], Train Loss: 35074275.3238\n",
      "Epoch [222/5000], Validation Loss: 63765287.5447\n",
      "Epoch [242/5000], Validation Loss: 63765287.5447\n",
      "Epoch [262/5000], Validation Loss: 63765287.5447\n",
      "Epoch [282/5000], Validation Loss: 63765275.0569\n",
      "new smallest validation loss\n",
      "Epoch [301/5000], Train Loss: 34846193.4012\n",
      "Epoch [302/5000], Train Loss: 34617107.2912\n",
      "Epoch [302/5000], Validation Loss: 63765270.8943\n",
      "new smallest validation loss\n",
      "Epoch [303/5000], Train Loss: 35301655.4623\n",
      "Epoch [322/5000], Validation Loss: 63765270.8943\n",
      "Epoch [342/5000], Validation Loss: 63765266.7317\n",
      "new smallest validation loss\n",
      "Epoch [362/5000], Validation Loss: 63765262.5691\n",
      "new smallest validation loss\n",
      "Epoch [382/5000], Validation Loss: 63765241.7561\n",
      "new smallest validation loss\n",
      "Epoch [401/5000], Train Loss: 35519244.5132\n",
      "Epoch [402/5000], Train Loss: 35267421.3279\n",
      "Epoch [402/5000], Validation Loss: 63765237.5935\n",
      "new smallest validation loss\n",
      "Epoch [403/5000], Train Loss: 35517531.7637\n",
      "Epoch [422/5000], Validation Loss: 63765229.2683\n",
      "new smallest validation loss\n",
      "Epoch [442/5000], Validation Loss: 63765216.7805\n",
      "new smallest validation loss\n",
      "Epoch [462/5000], Validation Loss: 63765212.6179\n",
      "new smallest validation loss\n",
      "Epoch [482/5000], Validation Loss: 63765204.2927\n",
      "new smallest validation loss\n",
      "Epoch [501/5000], Train Loss: 34603984.0326\n",
      "Epoch [502/5000], Train Loss: 34834504.9939\n",
      "Epoch [502/5000], Validation Loss: 63765195.9675\n",
      "new smallest validation loss\n",
      "Epoch [503/5000], Train Loss: 34833595.6986\n",
      "Epoch [522/5000], Validation Loss: 63765183.4797\n",
      "new smallest validation loss\n",
      "Epoch [542/5000], Validation Loss: 63765154.3415\n",
      "new smallest validation loss\n",
      "Epoch [562/5000], Validation Loss: 63765146.0163\n",
      "new smallest validation loss\n",
      "Epoch [582/5000], Validation Loss: 63765137.6911\n",
      "new smallest validation loss\n",
      "Epoch [601/5000], Train Loss: 33487610.7862\n",
      "Epoch [602/5000], Train Loss: 34629165.8819\n",
      "Epoch [602/5000], Validation Loss: 63765121.0407\n",
      "new smallest validation loss\n",
      "Epoch [603/5000], Train Loss: 34388756.3340\n",
      "Epoch [622/5000], Validation Loss: 63765129.3659\n",
      "Epoch [642/5000], Validation Loss: 63765096.0650\n",
      "new smallest validation loss\n",
      "Epoch [662/5000], Validation Loss: 63765066.9268\n",
      "new smallest validation loss\n",
      "Epoch [682/5000], Validation Loss: 63765054.4390\n",
      "new smallest validation loss\n",
      "Epoch [701/5000], Train Loss: 33933693.1324\n",
      "Epoch [702/5000], Train Loss: 35301573.0835\n",
      "Epoch [702/5000], Validation Loss: 63765029.4634\n",
      "new smallest validation loss\n",
      "Epoch [703/5000], Train Loss: 35289683.4216\n",
      "Epoch [722/5000], Validation Loss: 63765008.6504\n",
      "new smallest validation loss\n",
      "Epoch [742/5000], Validation Loss: 63765012.8130\n",
      "Epoch [762/5000], Validation Loss: 63764967.0244\n",
      "new smallest validation loss\n",
      "Epoch [782/5000], Validation Loss: 63764942.0488\n",
      "new smallest validation loss\n",
      "Epoch [801/5000], Train Loss: 34388191.1527\n",
      "Epoch [802/5000], Train Loss: 35531699.3564\n",
      "Epoch [802/5000], Validation Loss: 63764896.2602\n",
      "new smallest validation loss\n",
      "Epoch [803/5000], Train Loss: 34619125.0509\n",
      "Epoch [822/5000], Validation Loss: 63764846.3089\n",
      "new smallest validation loss\n",
      "Epoch [842/5000], Validation Loss: 63764837.9837\n",
      "new smallest validation loss\n",
      "Epoch [862/5000], Validation Loss: 63764804.6829\n",
      "new smallest validation loss\n",
      "Epoch [882/5000], Validation Loss: 63764783.8699\n",
      "new smallest validation loss\n",
      "Epoch [901/5000], Train Loss: 34846303.9348\n",
      "Epoch [902/5000], Train Loss: 36177601.3035\n",
      "Epoch [902/5000], Validation Loss: 63764713.1057\n",
      "new smallest validation loss\n",
      "Epoch [903/5000], Train Loss: 35061131.2098\n",
      "Epoch [922/5000], Validation Loss: 63764708.9431\n",
      "new smallest validation loss\n",
      "Epoch [942/5000], Validation Loss: 63764675.6423\n",
      "new smallest validation loss\n",
      "Epoch [962/5000], Validation Loss: 63764642.3415\n",
      "new smallest validation loss\n",
      "Epoch [982/5000], Validation Loss: 63764604.8780\n",
      "new smallest validation loss\n",
      "Epoch [1001/5000], Train Loss: 34401079.7882\n",
      "Epoch [1002/5000], Train Loss: 34857502.2403\n",
      "Epoch [1002/5000], Validation Loss: 63764588.2276\n",
      "new smallest validation loss\n",
      "Epoch [1003/5000], Train Loss: 35313736.9939\n",
      "Epoch [1022/5000], Validation Loss: 63764513.3008\n",
      "new smallest validation loss\n",
      "Epoch [1042/5000], Validation Loss: 63764480.0000\n",
      "new smallest validation loss\n",
      "Epoch [1062/5000], Validation Loss: 63764450.8618\n",
      "new smallest validation loss\n",
      "Epoch [1082/5000], Validation Loss: 63764434.2114\n",
      "new smallest validation loss\n",
      "Epoch [1101/5000], Train Loss: 34605694.1752\n",
      "Epoch [1102/5000], Train Loss: 34376096.0652\n",
      "Epoch [1102/5000], Validation Loss: 63764396.7480\n",
      "new smallest validation loss\n",
      "Epoch [1103/5000], Train Loss: 34628504.7658\n",
      "Epoch [1122/5000], Validation Loss: 63764317.6585\n",
      "new smallest validation loss\n",
      "Epoch [1142/5000], Validation Loss: 63764292.6829\n",
      "new smallest validation loss\n",
      "Epoch [1162/5000], Validation Loss: 63764280.1951\n",
      "new smallest validation loss\n",
      "Epoch [1182/5000], Validation Loss: 63764217.7561\n",
      "new smallest validation loss\n",
      "Epoch [1201/5000], Train Loss: 35061661.9796\n",
      "Epoch [1202/5000], Train Loss: 35987067.8289\n",
      "Epoch [1202/5000], Validation Loss: 63764209.4309\n",
      "new smallest validation loss\n",
      "Epoch [1203/5000], Train Loss: 33967493.9959\n",
      "Epoch [1222/5000], Validation Loss: 63764192.7805\n",
      "new smallest validation loss\n",
      "Epoch [1242/5000], Validation Loss: 63764126.1789\n",
      "new smallest validation loss\n",
      "Epoch [1262/5000], Validation Loss: 63764097.0407\n",
      "new smallest validation loss\n",
      "Epoch [1282/5000], Validation Loss: 63764030.4390\n",
      "new smallest validation loss\n",
      "Epoch [1301/5000], Train Loss: 34387931.5031\n",
      "Epoch [1302/5000], Train Loss: 33954665.3198\n",
      "Epoch [1302/5000], Validation Loss: 63763959.6748\n",
      "new smallest validation loss\n",
      "Epoch [1303/5000], Train Loss: 34172149.0509\n",
      "Epoch [1322/5000], Validation Loss: 63763918.0488\n",
      "new smallest validation loss\n",
      "Epoch [1342/5000], Validation Loss: 63763901.3984\n",
      "new smallest validation loss\n",
      "Epoch [1362/5000], Validation Loss: 63763822.3089\n",
      "new smallest validation loss\n",
      "Epoch [1382/5000], Validation Loss: 63763755.7073\n",
      "new smallest validation loss\n",
      "Epoch [1401/5000], Train Loss: 34400241.4012\n",
      "Epoch [1402/5000], Train Loss: 34400227.8452\n",
      "Epoch [1402/5000], Validation Loss: 63763705.7561\n",
      "new smallest validation loss\n",
      "Epoch [1403/5000], Train Loss: 33932313.5479\n",
      "Epoch [1422/5000], Validation Loss: 63763684.9431\n",
      "new smallest validation loss\n",
      "Epoch [1442/5000], Validation Loss: 63763655.8049\n",
      "new smallest validation loss\n",
      "Epoch [1462/5000], Validation Loss: 63763585.0407\n",
      "new smallest validation loss\n",
      "Epoch [1482/5000], Validation Loss: 63763514.2764\n",
      "new smallest validation loss\n",
      "Epoch [1501/5000], Train Loss: 35060306.3788\n",
      "Epoch [1502/5000], Train Loss: 34169966.5336\n",
      "Epoch [1502/5000], Validation Loss: 63763406.0488\n",
      "new smallest validation loss\n",
      "Epoch [1503/5000], Train Loss: 35288008.7332\n",
      "Epoch [1522/5000], Validation Loss: 63763393.5610\n",
      "new smallest validation loss\n",
      "Epoch [1542/5000], Validation Loss: 63763372.7480\n",
      "new smallest validation loss\n",
      "Epoch [1562/5000], Validation Loss: 63763243.7073\n",
      "new smallest validation loss\n",
      "Epoch [1582/5000], Validation Loss: 63763293.6585\n",
      "Epoch [1601/5000], Train Loss: 34626920.7984\n",
      "Epoch [1602/5000], Train Loss: 34183965.7189\n",
      "Epoch [1602/5000], Validation Loss: 63763272.8455\n",
      "Epoch [1603/5000], Train Loss: 34832445.5234\n",
      "Epoch [1622/5000], Validation Loss: 63763243.7073\n",
      "Epoch [1642/5000], Validation Loss: 63763122.9919\n",
      "new smallest validation loss\n",
      "Epoch [1662/5000], Validation Loss: 63763106.3415\n",
      "new smallest validation loss\n",
      "Epoch [1682/5000], Validation Loss: 63763077.2033\n",
      "new smallest validation loss\n",
      "Epoch [1701/5000], Train Loss: 35287560.3422\n",
      "Epoch [1702/5000], Train Loss: 34386703.1202\n",
      "Epoch [1702/5000], Validation Loss: 63762985.6260\n",
      "new smallest validation loss\n",
      "Epoch [1703/5000], Train Loss: 34171865.4175\n",
      "Epoch [1722/5000], Validation Loss: 63762989.7886\n",
      "Epoch [1742/5000], Validation Loss: 63762964.8130\n",
      "new smallest validation loss\n",
      "Epoch [1762/5000], Validation Loss: 63762981.4634\n",
      "Epoch [1782/5000], Validation Loss: 63762914.8618\n",
      "new smallest validation loss\n",
      "Epoch [1801/5000], Train Loss: 33931561.1894\n",
      "Epoch [1802/5000], Train Loss: 35061110.3544\n",
      "Epoch [1802/5000], Validation Loss: 63762706.7317\n",
      "new smallest validation loss\n",
      "Epoch [1803/5000], Train Loss: 34183604.9206\n",
      "Epoch [1822/5000], Validation Loss: 63762710.8943\n",
      "Epoch [1842/5000], Validation Loss: 63762698.4065\n",
      "new smallest validation loss\n",
      "Epoch [1862/5000], Validation Loss: 63762648.4553\n",
      "new smallest validation loss\n",
      "Epoch [1882/5000], Validation Loss: 63762494.4390\n",
      "new smallest validation loss\n",
      "Epoch [1901/5000], Train Loss: 34603919.3809\n",
      "Epoch [1902/5000], Train Loss: 34158856.8635\n",
      "Epoch [1902/5000], Validation Loss: 63762427.8374\n",
      "new smallest validation loss\n",
      "Epoch [1903/5000], Train Loss: 34146121.5153\n",
      "Epoch [1922/5000], Validation Loss: 63762373.7236\n",
      "new smallest validation loss\n",
      "Epoch [1942/5000], Validation Loss: 63762257.1707\n",
      "new smallest validation loss\n",
      "Epoch [1962/5000], Validation Loss: 63762344.5854\n",
      "Epoch [1982/5000], Validation Loss: 63762382.0488\n",
      "Epoch [2001/5000], Train Loss: 34385975.2668\n",
      "Epoch [2002/5000], Train Loss: 34158809.9389\n",
      "Epoch [2002/5000], Validation Loss: 63762186.4065\n",
      "new smallest validation loss\n",
      "Epoch [2003/5000], Train Loss: 33737206.0937\n",
      "Epoch [2022/5000], Validation Loss: 63762190.5691\n",
      "Epoch [2042/5000], Validation Loss: 63762111.4797\n",
      "new smallest validation loss\n",
      "Epoch [2062/5000], Validation Loss: 63762107.3171\n",
      "new smallest validation loss\n",
      "Epoch [2082/5000], Validation Loss: 63762007.4146\n",
      "new smallest validation loss\n",
      "Epoch [2101/5000], Train Loss: 34591681.4338\n",
      "Epoch [2102/5000], Train Loss: 34385349.6049\n",
      "Epoch [2102/5000], Validation Loss: 63761920.0000\n",
      "new smallest validation loss\n",
      "Epoch [2103/5000], Train Loss: 34386232.8310\n",
      "Epoch [2122/5000], Validation Loss: 63761874.2114\n",
      "new smallest validation loss\n",
      "Epoch [2142/5000], Validation Loss: 63761820.0976\n",
      "new smallest validation loss\n",
      "Epoch [2162/5000], Validation Loss: 63761895.0244\n",
      "Epoch [2182/5000], Validation Loss: 63761666.0813\n",
      "new smallest validation loss\n",
      "Epoch [2201/5000], Train Loss: 35299012.0407\n",
      "Epoch [2202/5000], Train Loss: 34818650.7210\n",
      "Epoch [2202/5000], Validation Loss: 63761661.9187\n",
      "new smallest validation loss\n",
      "Epoch [2203/5000], Train Loss: 34169942.5499\n",
      "Epoch [2222/5000], Validation Loss: 63761657.7561\n",
      "new smallest validation loss\n",
      "Epoch [2242/5000], Validation Loss: 63761549.5285\n",
      "new smallest validation loss\n",
      "Epoch [2262/5000], Validation Loss: 63761595.3171\n",
      "Epoch [2282/5000], Validation Loss: 63761632.7805\n",
      "Epoch [2301/5000], Train Loss: 34615234.4766\n",
      "Epoch [2302/5000], Train Loss: 35298150.7128\n",
      "Epoch [2302/5000], Validation Loss: 63761557.8537\n",
      "Epoch [2303/5000], Train Loss: 34612707.8452\n",
      "Epoch [2322/5000], Validation Loss: 63761562.0163\n",
      "Epoch [2342/5000], Validation Loss: 63761503.7398\n",
      "new smallest validation loss\n",
      "Epoch [2362/5000], Validation Loss: 63761320.5854\n",
      "new smallest validation loss\n",
      "Epoch [2382/5000], Validation Loss: 63761212.3577\n",
      "new smallest validation loss\n",
      "Epoch [2401/5000], Train Loss: 33496403.4216\n",
      "Epoch [2402/5000], Train Loss: 35731859.5519\n",
      "Epoch [2402/5000], Validation Loss: 63761129.1057\n",
      "new smallest validation loss\n",
      "Epoch [2403/5000], Train Loss: 33951557.8656\n",
      "Epoch [2422/5000], Validation Loss: 63761104.1301\n",
      "new smallest validation loss\n",
      "Epoch [2442/5000], Validation Loss: 63761191.5447\n",
      "Epoch [2462/5000], Validation Loss: 63761070.8293\n",
      "new smallest validation loss\n",
      "Epoch [2482/5000], Validation Loss: 63760941.7886\n",
      "new smallest validation loss\n",
      "Epoch [2501/5000], Train Loss: 34169080.1792\n",
      "Epoch [2502/5000], Train Loss: 35082187.8615\n",
      "Epoch [2502/5000], Validation Loss: 63760958.4390\n",
      "Epoch [2503/5000], Train Loss: 35755448.0489\n",
      "Epoch [2522/5000], Validation Loss: 63760983.4146\n",
      "Epoch [2542/5000], Validation Loss: 63760920.9756\n",
      "new smallest validation loss\n",
      "Epoch [2562/5000], Validation Loss: 63760750.3089\n",
      "new smallest validation loss\n",
      "Epoch [3801/5000], Train Loss: 34571041.8900\n",
      "Epoch [3802/5000], Train Loss: 33682134.8106\n",
      "Epoch [3802/5000], Validation Loss: 63735832.9756\n",
      "Epoch [3803/5000], Train Loss: 34561457.7923\n",
      "Epoch [3822/5000], Validation Loss: 63736078.5691\n",
      "Epoch [3842/5000], Validation Loss: 63735212.7480\n",
      "new smallest validation loss\n",
      "Epoch [3862/5000], Validation Loss: 63734467.6423\n",
      "new smallest validation loss\n",
      "Epoch [3882/5000], Validation Loss: 63735275.1870\n",
      "Epoch [3901/5000], Train Loss: 34354459.6334\n",
      "Epoch [3902/5000], Train Loss: 33454404.5621\n",
      "Epoch [3902/5000], Validation Loss: 63734272.0000\n",
      "new smallest validation loss\n",
      "Epoch [3903/5000], Train Loss: 35015512.1141\n",
      "Epoch [3922/5000], Validation Loss: 63733889.0407\n",
      "new smallest validation loss\n",
      "Epoch [3942/5000], Validation Loss: 63734388.5528\n",
      "Epoch [3962/5000], Validation Loss: 63734717.3984\n",
      "Epoch [3982/5000], Validation Loss: 63734063.8699\n",
      "Epoch [4001/5000], Train Loss: 35026321.4664\n",
      "Epoch [4002/5000], Train Loss: 33680501.8330\n",
      "Epoch [4002/5000], Validation Loss: 63734005.5935\n",
      "Epoch [4003/5000], Train Loss: 33692585.4501\n",
      "Epoch [4022/5000], Validation Loss: 63733668.4228\n",
      "new smallest validation loss\n",
      "Epoch [4042/5000], Validation Loss: 63733335.4146\n",
      "new smallest validation loss\n",
      "Epoch [4062/5000], Validation Loss: 63733019.0569\n",
      "new smallest validation loss\n",
      "Epoch [4082/5000], Validation Loss: 63732502.8943\n",
      "new smallest validation loss\n",
      "Epoch [4101/5000], Train Loss: 34365099.0143\n",
      "Epoch [4102/5000], Train Loss: 35241185.2383\n",
      "Epoch [4102/5000], Validation Loss: 63732465.4309\n",
      "new smallest validation loss\n",
      "Epoch [4103/5000], Train Loss: 35026005.5071\n",
      "Epoch [4122/5000], Validation Loss: 63732240.6504\n",
      "new smallest validation loss\n",
      "Epoch [4142/5000], Validation Loss: 63733364.5528\n",
      "Epoch [4162/5000], Validation Loss: 63731141.7236\n",
      "new smallest validation loss\n",
      "Epoch [4182/5000], Validation Loss: 63731075.1220\n",
      "new smallest validation loss\n",
      "Epoch [4201/5000], Train Loss: 34579540.4644\n",
      "Epoch [4202/5000], Train Loss: 35024885.5723\n",
      "Epoch [4202/5000], Validation Loss: 63734151.2846\n",
      "Epoch [4203/5000], Train Loss: 34136394.5580\n",
      "Epoch [4222/5000], Validation Loss: 63733156.4228\n",
      "Epoch [4242/5000], Validation Loss: 63731632.9106\n",
      "Epoch [4262/5000], Validation Loss: 63731016.8455\n",
      "new smallest validation loss\n",
      "Epoch [4282/5000], Validation Loss: 63730200.9756\n",
      "new smallest validation loss\n",
      "Epoch [4301/5000], Train Loss: 34821305.6130\n",
      "Epoch [4302/5000], Train Loss: 35708944.6843\n",
      "Epoch [4302/5000], Validation Loss: 63730916.9431\n",
      "Epoch [4303/5000], Train Loss: 35697486.2077\n",
      "Epoch [4322/5000], Validation Loss: 63731782.7642\n",
      "Epoch [4342/5000], Validation Loss: 63730758.7642\n",
      "Epoch [4362/5000], Validation Loss: 63730034.4715\n",
      "new smallest validation loss\n",
      "Epoch [4382/5000], Validation Loss: 63731533.0081\n",
      "Epoch [4401/5000], Train Loss: 35011245.0998\n",
      "Epoch [4402/5000], Train Loss: 35240121.6130\n",
      "Epoch [4402/5000], Validation Loss: 63730379.9675\n",
      "Epoch [4403/5000], Train Loss: 35035354.9817\n",
      "Epoch [4422/5000], Validation Loss: 63729992.8455\n",
      "new smallest validation loss\n",
      "Epoch [4442/5000], Validation Loss: 63730767.0894\n",
      "Epoch [4462/5000], Validation Loss: 63727982.3089\n",
      "new smallest validation loss\n",
      "Epoch [4482/5000], Validation Loss: 63729081.2358\n",
      "Epoch [4501/5000], Train Loss: 33883045.2790\n",
      "Epoch [4502/5000], Train Loss: 34134286.0774\n",
      "Epoch [4502/5000], Validation Loss: 63727420.3577\n",
      "new smallest validation loss\n",
      "Epoch [4503/5000], Train Loss: 33700645.5397\n",
      "Epoch [4522/5000], Validation Loss: 63728906.4065\n",
      "Epoch [4542/5000], Validation Loss: 63730176.0000\n",
      "Epoch [4562/5000], Validation Loss: 63729809.6911\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "\n",
    "input_size = 18658  \n",
    "latent_size = 1024 * 2 * 2   \n",
    "model = LargeVAE(input_size, latent_size).to(device) \n",
    "\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate , weight_decay=1e-5)\n",
    "num_epochs = 5000 \n",
    "\n",
    "min_validation_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, _ in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mean, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mean, logvar)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    if epoch % 100 < 3:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to(device)  # Move data to the appropriate device\n",
    "            recon_batch, mean, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mean, logvar)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    if epoch % 20 == 1:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "        if avg_val_loss < min_validation_loss:\n",
    "            min_validation_loss = avg_val_loss\n",
    "            print(\"new smallest validation loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b9e62-3ca6-44d7-9d8c-1cdb3942cac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vae_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dd076-133f-4657-8793-e040647bcc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_to_extract = 5\n",
    "extracted_rows = X[:rows_to_extract]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(extracted_rows.numpy())\n",
    "\n",
    "csv_file_path = 'extracted_rows.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b4db0-159a-4372-82a6-8ecda6264045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
